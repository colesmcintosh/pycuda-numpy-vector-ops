{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colesmcintosh/pycuda-numpy-vector-ops/blob/main/Accelerating_NumPy_Vector_Operations_with_PyCUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyg48_lHIZG6"
      },
      "source": [
        "# ğŸš€ Accelerating NumPy Vector Operations with PyCUDA\n",
        "\n",
        "This notebook demonstrates how to accelerate large-scale NumPy operations using GPU programming in Python via [PyCUDA](https://documen.tician.de/pycuda/).\n",
        "\n",
        "We compare traditional CPU-based NumPy operations with a GPU-accelerated fused multiply-add (FMA) operation:\n",
        "\n",
        "> The operation is defined as $c[i] = a[i] \\times b[i] + d[i]$.\n",
        "\n",
        "The notebook uses:\n",
        "- Pinned (page-locked) memory for faster host-device transfers\n",
        "- CUDA streams for asynchronous execution\n",
        "- Event timing for accurate benchmarks\n",
        "\n",
        "The result is a fast, validated comparison of NumPy vs PyCUDA performance."
      ],
      "id": "Hyg48_lHIZG6"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdIRzVxWIZG8",
        "outputId": "906c49cc-f9f3-46a0-8093-e053efa69d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.7/1.7 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda --quiet"
      ],
      "id": "GdIRzVxWIZG8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcMFsr8FIZG8"
      },
      "source": [
        "## CUDA Kernel: Fused Multiply-Add\n",
        "We use a fused multiply-add operation"
      ],
      "id": "CcMFsr8FIZG8"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XnXhWTZ6IZG8"
      },
      "outputs": [],
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "kernel_code = \"\"\"\n",
        "__global__ void fused_op(float *a, float *b, float *d, float *c, int n) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] * b[idx] + d[idx];\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "mod = SourceModule(kernel_code)\n",
        "fused_op = mod.get_function(\"fused_op\")"
      ],
      "id": "XnXhWTZ6IZG8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQtnp4o3IZG9"
      },
      "source": [
        "## Set Array Size and Grid Configuration"
      ],
      "id": "DQtnp4o3IZG9"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dmaiPUH4IZG9"
      },
      "outputs": [],
      "source": [
        "N = 10_000_000\n",
        "threads_per_block = 256\n",
        "blocks_per_grid = (N + threads_per_block - 1) // threads_per_block"
      ],
      "id": "dmaiPUH4IZG9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCiYGPRRIZG9"
      },
      "source": [
        "## Allocate GPU Buffers and Structured Pinned Memory"
      ],
      "id": "XCiYGPRRIZG9"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e7vEax96IZG9"
      },
      "outputs": [],
      "source": [
        "a = cuda.pagelocked_empty(N, dtype=np.float32)\n",
        "b = cuda.pagelocked_empty(N, dtype=np.float32)\n",
        "d = cuda.pagelocked_empty(N, dtype=np.float32)\n",
        "c = cuda.pagelocked_empty(N, dtype=np.float32)\n",
        "\n",
        "x = np.linspace(1, 100, N).astype(np.float32)\n",
        "a[:] = np.sin(x)\n",
        "b[:] = np.log(x)\n",
        "d[:] = np.exp(-x / 50)"
      ],
      "id": "e7vEax96IZG9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oG01ku7IZG-"
      },
      "source": [
        "## Launch CUDA Kernel with Asynchronous Transfers"
      ],
      "id": "6oG01ku7IZG-"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sJb1Rts7IZG-"
      },
      "outputs": [],
      "source": [
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "d_gpu = cuda.mem_alloc(d.nbytes)\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "stream = cuda.Stream()\n",
        "start_event = cuda.Event()\n",
        "end_event = cuda.Event()\n",
        "start_event.record(stream)\n",
        "\n",
        "cuda.memcpy_htod_async(a_gpu, a, stream)\n",
        "cuda.memcpy_htod_async(b_gpu, b, stream)\n",
        "cuda.memcpy_htod_async(d_gpu, d, stream)\n",
        "\n",
        "fused_op(a_gpu, b_gpu, d_gpu, c_gpu, np.int32(N),\n",
        "         block=(threads_per_block, 1, 1),\n",
        "         grid=(blocks_per_grid, 1, 1),\n",
        "         stream=stream)\n",
        "\n",
        "cuda.memcpy_dtoh_async(c, c_gpu, stream)\n",
        "end_event.record(stream)\n",
        "end_event.synchronize()\n",
        "\n",
        "kernel_time = start_event.time_till(end_event) * 1e-3"
      ],
      "id": "sJb1Rts7IZG-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1qr7kYrIZG-"
      },
      "source": [
        "## Validate GPU Results and Report Timing"
      ],
      "id": "L1qr7kYrIZG-"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjZ0NgCAIZG-",
        "outputId": "53beb3f4-ea2a-4d80-fd6f-10bb10efa755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Results match within tolerance.\n",
            "NumPy FMA took: 0.030167 seconds\n",
            "GPU (FMA kernel + overlap) time: 0.016037 seconds\n",
            "ğŸš€ Speedup: 1.88Ã—\n"
          ]
        }
      ],
      "source": [
        "# CPU reference\n",
        "start = time.time()\n",
        "c_cpu = a * b + d\n",
        "end = time.time()\n",
        "cpu_time = end - start\n",
        "\n",
        "# Compare with both relative and absolute tolerance\n",
        "if np.allclose(c, c_cpu, rtol=1e-4, atol=1e-6):\n",
        "    print(\"âœ… Results match within tolerance.\")\n",
        "else:\n",
        "    print(\"âŒ Results differ. Showing mismatched values:\")\n",
        "    diffs = np.abs(c - c_cpu)\n",
        "    idx = np.where(diffs > 1e-4)[0]\n",
        "    for i in idx[:10]:  # Print first 10 differences\n",
        "        print(f\"Index {i}: GPU={c[i]:.6f}, CPU={c_cpu[i]:.6f}, Î”={diffs[i]:.2e}\")\n",
        "    print(f\"Total mismatches: {len(idx)}\")\n",
        "\n",
        "# Print timings\n",
        "print(f\"NumPy FMA took: {cpu_time:.6f} seconds\")\n",
        "print(f\"GPU (FMA kernel + overlap) time: {kernel_time:.6f} seconds\")\n",
        "print(f\"ğŸš€ Speedup: {cpu_time / kernel_time:.2f}Ã—\")"
      ],
      "id": "mjZ0NgCAIZG-"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}